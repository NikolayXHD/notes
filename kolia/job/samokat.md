MLR Machine Learning Ranking

- Dataset
  - LETOR Learning to Rank for Information Retrieval

https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4
https://towardsdatascience.com/breaking-down-mean-average-precision-map-ae462f623a52

- [ ] Чтобы содержательно ответить на вопрос, как мы измеряли качество поиска
  похожих текстов.
  - [ ] Посчитать чисто для Sentence Transformers
  - [ ] Посчитать mAP для нашей связки VIS + Sentence Transformers
  - Чтобы не портить карму, признаться что мерил не я, но спец. освежил
    в памяти перед собесом.

- [ ] классический ML
  - [v] Gradient Boosting
    https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502
    Итеративно строим деревья решения, оптимизирующие произвольный дифференцируемый Loss
  - [v] Naive Bayes Regression
    https://towardsdatascience.com/the-not-so-naive-bayes-b795eaa0f69b
    - Делает бинарную классификацию на основе значений зависимых переменных,
      в предположении, что они независимы, хотя это почти всегда неверно, отсюда
      Naive в названии.
    - Несмотря на нарушение независимости на практике, работает хорошо.
    - Различают варианты для разных типов зависимой переменной
      - Непрерываная величина с Гауссовым распределением
      - Дискретная величина с конечным набором значений Multinomial
      - Булева величина, bernoulli naive bayes
  - [v] Complement Naive Bayes
    Модификация Naive Bayes Regression для случая несбалансированных классов
    в обучающей выборке.
    Считается, что проявляет себя лучше NB в задачах классификации текста.
    Доказательтсво эмпирическое.
    - Для каждого класса считаем вес, wc, смысл которого - вероятность НЕ попасть
      в класс.
    - Во время inference предсказываем класс, для которого вероятность НЕ попасть
      в класс наименьшая.

Метрики
-------

- [v] mean Average Precision
  Метрика для бинарного значения релевантности Да / Нет
  - Для одного запроса и выдачи `AP = Sum( (R[k] - R[k-1]) * P[k] )`
    - `R[k]` - Recall для элементов выдачи 1..k
    - `P[k]` - Precision для элементов выдачи 1..k
  - `AP` Достигает `1`, если в топе все релевантные документы
  - mAP отдаёт средний AP по нескольким запросам
- [v] MRR, Mean Reverse Rank
  - Для бинарной релевантности
  - Среднее по запросам значение величины 1 / rank, где rank положение в выдаче первого
    релевантного документа.

- [v] Discounted Cumulative Gain - метрика для дискретной релевантности, напр. 0..4
  - Каждый элемент выдачи получает `Gain = 2 ^ y[k] - 1`
    `-1` чтобы минимум  Gain равнялся 0
  - Каждый элемент выдачи получает вес Discount = 1 / log2(k + 1)
    считаем нумерация `k` идёт от `1`, чтобы не было деления на `0`
  - Считаем взвешенную сумму Gain с весом Discount
  - Делим на такую же сумму для идеальной выдачи, чтобы максимум не превысил `1`
    получаем уже нормализованный DCG, т.е. NDCG

MLR
---

- [v] Pointwise
  Хотим предсказывать ranking score для конкретного запрос + документа => задача сводится к регрессии
  Проблема в том, что где на практике взять размеченный score?
- [v] Pairwise
  - Сводим к задаче бинарной классификации, ввод запрос + пара документов, вывод кто релевантнее
  - Источником данных может служить реально совершённый выбор человека
  - На практике работает лучше чем Pointwise
- [v] Listwise
  - теоретически, должно быть выгоднее подавать на обучение ранжированный список
  - Источником данных могут служить анкеты и действия пользователя
  - Проблема в том, как получить дифференцируемый Loss на списке
    - Вероятностный ranking score.
      - Сделаем так, что на выходе мы предсказываем ranking score документов согласно
        гладкой плотности вероятности. Тогда ranking loss оказывается дифференцируемой
        функцией от предсказаного среднего значения ranking score.
      - Страдает от локальных экстремумов, Loss не выпуклый
      - Пример SoftRank
    - Предсказать целый список, строить loss от вероятностей вариантов списка
      - Проблема в комбинаторном росте количества возможных списков от длины
    - Градиент неявной функции LambdaRank. 
      - LambdaMART использует тот же градиент, но для GradientBoosting вместо нейронки,
        результат SoTA
    - Обобщающая работа про LambdaLoss показывает как строить оптимизацию для
      заданной метрики в духе LambdaRank


