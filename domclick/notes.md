# tf-idf

для корпуса строим словарь токенов

IDF
Вектор
1 / Распространённость токена корпусе

В каком количестве документов корпуса встречается токен
Обычно берут логарифм
Часто отбрасывают самые распространённые токены

TF
для документа строим разреженный вектор, сколько раз токен встретился в
документе

IF-IDF документа = покоординатное произведение TF * IDF

Релевантность
TF-IDF = query = (TF_QUERY * TF_RESPONSE * IDF).sum()

# w2v

Предсказываем слово по контесту
- n пред слов
- Continous BagOfWords: n пред и последующих слов
- SkipGram: предсказываем соседние слова с обеих сторон, с зазором < n

Как должна выглядеть нейронка.
1. Собственно эмбеддинги
2. Слой предсказанного токена. т.к. выбираем 1 из конечного множества, то
   аналогично многоклассовой классификации. Соотв лосс можно делать
   кросс-энтропию

Положительные примеры берём просто из корпуса
Отрицательные примеры конструируем, ставя рандомный токен в позицию, которую
нужно предсказать. Это не идельно, т.к. токен может оказаться верным, зато
очень просто и работает на практике.

# fasttext

Библиотека позволяет обучать эбмеддинги на вашем корпусе
Очень внятная документация
поддерживает CBoW, Skipgram
Только CPU
Можно n-gramm ы
можно subword-ы для готовности к незнакомым словам или потерянным пробелам
  дефолтное значение `-minn 3 -maxn 6`

# elmo

embedding-и из LSTM

# leaderboard

## Модели

### FRED-T5 1.7B
Русскоязычный вариант T5
Encoder-Decoder
Тип задачи контролируется префиксом
Translate English to German:
Применимость:
- не хватает знания, с какими префиксами обучена модель на задачи
  NLI в Russian SUPER Glue.
+ Должно влезть на GPU 16GB

можно спросить разработчиков, есть тг чат https://t.me/nlpcoreteam

В тексте "обучено как в оригинальной статье T5"
На практике, промт как в статье
mnli premise: blah hypothesis: blah target:
не работает

### FRED-T5 large finetune
Значительно слабее FRED-T5 1.7B
Напр DaNetQA 0.889 -> 0.799, это в 2 раза больше ошибок
Применимость: может пригодиться на проде, обученный на разметке от более
толстой модели.

### Golden Transformer v2.0
Ансамбль трансформеров + CatBoost
Примеры NLI - промтов
https://github.com/neverix/avengers-ensemble/blob/v2/ensemble.py
Применимость: нет
- штраф на порядок или 2 к усилиям на деплой
- штраф на порядок или 2 к задержке инференса
- штраф на порядок или 2 к нагрузке на инфраструктуру

### LLaMA-2 13B LoRA
Дообучили Llama2 на русских датасетах
LLaMA 13B LoRA
Есть примеры NLI prompt-ов
https://github.com/IlyaGusev/rulm/blob/master/self_instruct/src/benchmarks/eval_zs_rsg.py#L160C1-L160C1
На самом деле нужна вероятность, а не бинарный ответ.
Для этого стоит смотреть на вероятности 1-го токена вывода
Нас будут интересовать вероятности токенов "Да" и "Нет"
Применимость: дорого, 13B параметров => нужен TPU

4. YaLM p-tune
Прикольная идея P-tune, кажется можно применять к любым transformer
Применимость: нет, модель не в открытом доступе

## Термины

- LoRA Low Rank Adaptation
  Эффективная вариация процедуры Fine-Tuning
  W = W + ΔW
  ΔW = A·B
  A, B имеют более низкий ранг чем W
  Замораживаем W, обучаем низкоранговые A, B
- p-tuning
  Вместо ручного promt-engeneering-а, обучим модель, где
  LLM заморожена, а обучается эмбеддинг, полученный от некоторого промпта
  Таргет - метрика выдачи промт+замороженная модель
  требуется 100+ размеченных примеров
  На выходе имеем эмбеддинг, который можно подставить в исходную модель
  вместо подобранного prompt

## Задачи

https://russiansuperglue.com/tasks/

- LiDiRus (Russian Super GLUE) Linguistic Diagnostic for Russian
  переведённый SuperGLUE. GLUE, Super GLUE - размеченные датасеты NLI,
  сгруппированные по механизму языка, владение которым необходимо для
  правильного ответа.
- RCB Russian Commitment Bank
  NLI. Посылка - текст из газеты, новости или журнала
  Разметка - человеческая, Yandex.Toloka
- PARus Plausible Alternatives for Russian Language
  Датасет с выбором из 2х гипотез боеле вероятной
  Посылка - текст из газеты, новости или журнала
  Разметка - человеческая, Yandex.Toloka
- MuSeRC Multi Sentence Reading Comprehension
  Для правильного ответа всегда недостаточно 1 предложения
  Новости, учебники, сказки
  Посылка - несколько предложений
  Вопросы с бинарным да/нет ответом.
- TERRa Textual Entaliment Recognition for Russian
  NLI
  Новости, журналы, газеты
  Ручная разметка Yandex.Toloka
- Russian Words in Context
  2 предложения с одним и тем же словом.
  задача ответить в одном или в разном смысле слово упомянуто.
- RWSD Russian Winograd Schema Challenge
  Предложения с двусмысленностью, разрешение которой требует знания слов и
  рассуждения.
  Перевод и адаптация оригинального датасата выполнен Yandex.Toloka
- DaNetQA
  Бинарный вопрос + Абзац Википедии + Ответ
- RuCoS Russian reading comprehension with Commonsense reasoning
  Extractive QA, новости CNN / Daily Mail
